{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "import random\n",
    "print(os.listdir(\"../input\"))\n",
    "print(os.listdir())\n",
    "from tqdm import tqdm\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.callbacks import Callback, LearningRateScheduler, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import logging\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load traing data file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"../input/train_labels.csv\")\n",
    "labels.head()\n",
    "\n",
    "train = []\n",
    "for file in labels['name'].apply(lambda x: str(x) + '.jpg'):\n",
    "    train.append(['../input/train/{}'.format(file)])\n",
    "train = pd.DataFrame(train, columns=['file'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "004a19398e8a7835e294ab97b6486d4e236854f6"
   },
   "source": [
    "Add Response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ef70d1c411c7d1b2d8c3bc86ac0d9e4ed8b34ad2"
   },
   "outputs": [],
   "source": [
    "train['invasive'] = labels['invasive']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split training and validation data 80/20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "98ff66298af9dabd74cc1628b9bc0771de07b08b"
   },
   "outputs": [],
   "source": [
    "trainSample = train.sample(frac=0.8)\n",
    "validate = train[~train.file.isin(trainSample['file'])]\n",
    "\n",
    "trainSample.sort_index( inplace=True)\n",
    "validate.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "69aab953be99d0e946b7c9211d716fc700656381"
   },
   "source": [
    "Make Response arrays for Categorical Crossentropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2e828fec6c57b35eb10399582213265fca0dd1a4"
   },
   "outputs": [],
   "source": [
    "trainY = pd.DataFrame({'non': 1 - trainSample['invasive'], 'invasive' : trainSample['invasive']})\n",
    "valY = pd.DataFrame({'non': 1 - validate['invasive'], 'invasive' : validate['invasive']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training and validation images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "46e261226c45ecbcad367d5661f1f26c40c8104a"
   },
   "outputs": [],
   "source": [
    "def read_img(filepath, size):\n",
    "    img = image.load_img(os.path.join(filepath), target_size=size)\n",
    "    img = image.img_to_array(img)\n",
    "    return img\n",
    "\n",
    "INPUT_SIZE = 224\n",
    "trainX = np.zeros((len(trainSample), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\n",
    "for i, file in tqdm(enumerate(trainSample['file'])):\n",
    "    img = read_img(file, (INPUT_SIZE, INPUT_SIZE))\n",
    "    trainX[i] = img\n",
    "    \n",
    "valX =  np.zeros((len(validate), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\n",
    "for i, file in tqdm(enumerate(validate['file'])):\n",
    "    img = read_img(file, (INPUT_SIZE, INPUT_SIZE))\n",
    "    valX[i] = img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add preprocessing and data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6dc6e60c8fef9b83bed18477fce9a0f988457acb"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=90,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    #shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    preprocessing_function=preprocess_input)\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create AUC metri for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def auc_roc(y_true, y_pred):\n",
    "    value, update_op = tf.contrib.metrics.streaming_auc(y_pred, y_true)\n",
    "\n",
    "    metric_vars = [i for i in tf.local_variables() if 'auc_roc' in i.name.split('/')[1]]\n",
    "\n",
    "    for v in metric_vars:\n",
    "        tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)\n",
    "\n",
    "    with tf.control_dependencies([update_op]):\n",
    "        value = tf.identity(value)\n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Xception model and add dense output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e484c8068b561cd981c6bbc908158312ab635429"
   },
   "outputs": [],
   "source": [
    "basic_model = Xception(include_top=False, weights='imagenet', pooling='avg')\n",
    "\n",
    "input_tensor = basic_model.input\n",
    "# build top\n",
    "x = basic_model.output\n",
    "x = Dropout(.5)(x)\n",
    "x = Dense(2, activation='softmax')(x)\n",
    "\n",
    "best_model_file = 'XC-224x224.h5'\n",
    "model = Model(inputs=input_tensor, outputs=x)\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.W_regularizer = l2(1e-2)\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3711990f7cf5d35fc82fab8afaad4406c9e012f9"
   },
   "outputs": [],
   "source": [
    "best_model_file = 'XC-224x224.h5'\n",
    "model = Model(inputs=input_tensor, outputs=x)\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.W_regularizer = l2(1e-2)\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=RMSprop(1e-3), loss='categorical_crossentropy', metrics=[auc_roc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "182bc342344f2b3cdc1be068d2e38ff7048f14c1"
   },
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='auc_roc', patience=10, verbose=1, min_delta=1e-5),\n",
    "             ReduceLROnPlateau(monitor='auc_roc', factor=0.1, patience=5, cooldown=1, \n",
    "                               verbose=1, min_lr=1e-7),\n",
    "             ModelCheckpoint(filepath=best_model_file, verbose=1,\n",
    "                             save_best_only=True, save_weights_only=True, mode='auto')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "68aca143882db0c9b92f8aad4e0bd2e4ed47ec6a"
   },
   "outputs": [],
   "source": [
    "model.fit_generator(train_datagen.flow(trainX, trainY, batch_size=16), epochs=100, \n",
    "                    validation_data=val_datagen.flow(valX, valY, batch_size=16),\n",
    "                    callbacks=callbacks,\n",
    "                    steps_per_epoch = trainSample.shape[0]/16,\n",
    "                    validation_steps = validate.shape[0]/16,\n",
    "                    #workers=4,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b950a56678c3fc9f39711fde4f998c4bd5550bef"
   },
   "outputs": [],
   "source": [
    "test = []\n",
    "for file in os.listdir('../input/test'):\n",
    "    test.append(['../input/test/{}'.format(file)])\n",
    "test = pd.DataFrame(test, columns=['file'])\n",
    "test.sort_values('file',inplace=True)\n",
    "\n",
    "testX = np.zeros((len(test), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\n",
    "for i, file in tqdm(enumerate(test['file'])):\n",
    "    img = read_img(file, (INPUT_SIZE, INPUT_SIZE))\n",
    "    testX[i] = img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c224727c3c98e4a20842b73b378f121bc52facc0"
   },
   "source": [
    "Save Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d95d47c46154dfe5c7a167d9dbe0bcdcea30f097"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(val_datagen.flow(testX, shuffle=False,\n",
    "                                                       batch_size=1),\n",
    "                                     steps=testX.shape[0])\n",
    "\n",
    "pd.DataFrame({'name': test['file'], 'invasive': predictions[:, 1]}).to_csv('XC.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
